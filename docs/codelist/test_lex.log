[==========] Running 3 tests from 1 test suite.
[----------] Global test environment set-up.
[----------] 3 tests from LexTest
[ RUN      ] LexTest.isEmptyInitially
New line: S -> <a> A
currToken[S]
currToken[->]
currToken[<a>]
<a>.regexPattern=a
currToken[A]
New line: A -> <b> | EPSILON
currToken[A]
currToken[->]
currToken[<b>]
<b>.regexPattern=b
currToken[|]
currToken[EPSILON]
New line: E -> T A
currToken[E]
currToken[->]
currToken[T]
currToken[A]
New line: A -> <\+> T A | EPSILON
currToken[A]
currToken[->]
currToken[<\+>]
<\+>.regexPattern=\+
currToken[T]
currToken[A]
currToken[|]
currToken[EPSILON]
New line: B -> <\*> F B | EPSILON
currToken[B]
currToken[->]
currToken[<\*>]
<\*>.regexPattern=\*
currToken[F]
currToken[B]
currToken[|]
currToken[EPSILON]
New line: F -> <\(> E <\)> | N
currToken[F]
currToken[->]
currToken[<\(>]
<\(>.regexPattern=\(
currToken[E]
currToken[<\)>]
<\)>.regexPattern=\)
currToken[|]
currToken[N]
New line: N -> <[0-9]+>
currToken[N]
currToken[->]
currToken[<[0-9]+>]
<[0-9]+>.regexPattern=[0-9]+
New line: T -> F B
currToken[T]
currToken[->]
currToken[F]
currToken[B]
[       OK ] LexTest.isEmptyInitially (1 ms)
[ RUN      ] LexTest.tokenize1
New line: S -> <a> A
currToken[S]
currToken[->]
currToken[<a>]
<a>.regexPattern=a
currToken[A]
New line: A -> <b> | EPSILON
currToken[A]
currToken[->]
currToken[<b>]
<b>.regexPattern=b
currToken[|]
currToken[EPSILON]
New line: E -> T A
currToken[E]
currToken[->]
currToken[T]
currToken[A]
New line: A -> <\+> T A | EPSILON
currToken[A]
currToken[->]
currToken[<\+>]
<\+>.regexPattern=\+
currToken[T]
currToken[A]
currToken[|]
currToken[EPSILON]
New line: B -> <\*> F B | EPSILON
currToken[B]
currToken[->]
currToken[<\*>]
<\*>.regexPattern=\*
currToken[F]
currToken[B]
currToken[|]
currToken[EPSILON]
New line: F -> <\(> E <\)> | N
currToken[F]
currToken[->]
currToken[<\(>]
<\(>.regexPattern=\(
currToken[E]
currToken[<\)>]
<\)>.regexPattern=\)
currToken[|]
currToken[N]
New line: N -> <[0-9]+>
currToken[N]
currToken[->]
currToken[<[0-9]+>]
<[0-9]+>.regexPattern=[0-9]+
New line: T -> F B
currToken[T]
currToken[->]
currToken[F]
currToken[B]
Accepted tokens:
[-2, 0, BOTTOM OF STACK], [1, 1, <a>], [3, 2, <b>],
Tokenize [aaa bbb a]:
Tokens:
Current char: a, current token:
<a> matches a
cntMatch=1>0, expand token. Current char: a, current token: a
Current char: a, current token: a
cntMatch=0, stop appending char to current token a.
a: <a>
Current char: a, current token: a
cntMatch=0, stop appending char to current token a.
a: <a>
Current char:  , current token: a
cntMatch=0, stop appending char to current token a.
a: <a>
Current char: b, current token:
cntMatch=0, stop appending char to current token  .
Current char: b, current token: b
cntMatch=0, stop appending char to current token b.
b: <b>
Current char: b, current token: b
cntMatch=0, stop appending char to current token b.
b: <b>
Current char:  , current token: b
cntMatch=0, stop appending char to current token b.
b: <b>
Current char: a, current token:
cntMatch=0, stop appending char to current token  .
a: <a>

Tokenize [aan]:
This tokenization is expected to throw an exception.
Tokens:
Current char: a, current token:
<a> matches a
cntMatch=1>0, expand token. Current char: a, current token: a
Current char: a, current token: a
cntMatch=0, stop appending char to current token a.
a: <a>
Current char: n, current token: a
cntMatch=0, stop appending char to current token a.
a: <a>
ERROR: Invalid token: n
[       OK ] LexTest.tokenize1 (0 ms)
[ RUN      ] LexTest.tokenize2
New line: S -> <a> A
currToken[S]
currToken[->]
currToken[<a>]
<a>.regexPattern=a
currToken[A]
New line: A -> <b> | EPSILON
currToken[A]
currToken[->]
currToken[<b>]
<b>.regexPattern=b
currToken[|]
currToken[EPSILON]
New line: E -> T A
currToken[E]
currToken[->]
currToken[T]
currToken[A]
New line: A -> <\+> T A | EPSILON
currToken[A]
currToken[->]
currToken[<\+>]
<\+>.regexPattern=\+
currToken[T]
currToken[A]
currToken[|]
currToken[EPSILON]
New line: B -> <\*> F B | EPSILON
currToken[B]
currToken[->]
currToken[<\*>]
<\*>.regexPattern=\*
currToken[F]
currToken[B]
currToken[|]
currToken[EPSILON]
New line: F -> <\(> E <\)> | N
currToken[F]
currToken[->]
currToken[<\(>]
<\(>.regexPattern=\(
currToken[E]
currToken[<\)>]
<\)>.regexPattern=\)
currToken[|]
currToken[N]
New line: N -> <[0-9]+>
currToken[N]
currToken[->]
currToken[<[0-9]+>]
<[0-9]+>.regexPattern=[0-9]+
New line: T -> F B
currToken[T]
currToken[->]
currToken[F]
currToken[B]
Accepted tokens:
[-2, 0, BOTTOM OF STACK], [3, 1, <\+>], [5, 2, <\*>], [7, 3, <\(>], [8, 4, <\)>], [10, 5, <[0-9]+>],
Tokenize [1+2+3+]:
Tokens:
Current char: 1, current token:
<[0-9]+> matches 1
cntMatch=1>0, expand token. Current char: +, current token: 1
Current char: +, current token: 1
cntMatch=0, stop appending char to current token 1.
1: <[0-9]+>
Current char: 2, current token: +
cntMatch=0, stop appending char to current token +.
+: <\+>
Current char: +, current token: 2
cntMatch=0, stop appending char to current token 2.
2: <[0-9]+>
Current char: 3, current token: +
cntMatch=0, stop appending char to current token +.
+: <\+>
Current char: +, current token: 3
cntMatch=0, stop appending char to current token 3.
3: <[0-9]+>
+: <\+>


Tokenize [423*384*23]:
Tokens:
Current char: 4, current token:
<[0-9]+> matches 4
cntMatch=1>0, expand token. Current char: 2, current token: 4
Current char: 2, current token: 4
<[0-9]+> matches 42
cntMatch=1>0, expand token. Current char: 3, current token: 42
Current char: 3, current token: 42
<[0-9]+> matches 423
cntMatch=1>0, expand token. Current char: *, current token: 423
Current char: *, current token: 423
cntMatch=0, stop appending char to current token 423.
423: <[0-9]+>
Current char: 3, current token: *
cntMatch=0, stop appending char to current token *.
*: <\*>
Current char: 8, current token: 3
<[0-9]+> matches 38
cntMatch=1>0, expand token. Current char: 4, current token: 38
Current char: 4, current token: 38
<[0-9]+> matches 384
cntMatch=1>0, expand token. Current char: *, current token: 384
Current char: *, current token: 384
cntMatch=0, stop appending char to current token 384.
384: <[0-9]+>
Current char: 2, current token: *
cntMatch=0, stop appending char to current token *.
*: <\*>
Current char: 3, current token: 2
<[0-9]+> matches 23
cntMatch=1>0, expand token. Current char: , current token: 23
23: <[0-9]+>

Tokenize [(33+34)*45)32+8*(3*1+3)]:
Tokens:
Current char: (, current token:
<\(> matches (
cntMatch=1>0, expand token. Current char: 3, current token: (
Current char: 3, current token: (
cntMatch=0, stop appending char to current token (.
(: <\(>
Current char: 3, current token: 3
<[0-9]+> matches 33
cntMatch=1>0, expand token. Current char: +, current token: 33
Current char: +, current token: 33
cntMatch=0, stop appending char to current token 33.
33: <[0-9]+>
Current char: 3, current token: +
cntMatch=0, stop appending char to current token +.
+: <\+>
Current char: 4, current token: 3
<[0-9]+> matches 34
cntMatch=1>0, expand token. Current char: ), current token: 34
Current char: ), current token: 34
cntMatch=0, stop appending char to current token 34.
34: <[0-9]+>
Current char: *, current token: )
cntMatch=0, stop appending char to current token ).
): <\)>
Current char: 4, current token: *
cntMatch=0, stop appending char to current token *.
*: <\*>
Current char: 5, current token: 4
<[0-9]+> matches 45
cntMatch=1>0, expand token. Current char: ), current token: 45
Current char: ), current token: 45
cntMatch=0, stop appending char to current token 45.
45: <[0-9]+>
Current char: 3, current token: )
cntMatch=0, stop appending char to current token ).
): <\)>
Current char: 2, current token: 3
<[0-9]+> matches 32
cntMatch=1>0, expand token. Current char: +, current token: 32
Current char: +, current token: 32
cntMatch=0, stop appending char to current token 32.
32: <[0-9]+>
Current char: 8, current token: +
cntMatch=0, stop appending char to current token +.
+: <\+>
Current char: *, current token: 8
cntMatch=0, stop appending char to current token 8.
8: <[0-9]+>
Current char: (, current token: *
cntMatch=0, stop appending char to current token *.
*: <\*>
Current char: 3, current token: (
cntMatch=0, stop appending char to current token (.
(: <\(>
Current char: *, current token: 3
cntMatch=0, stop appending char to current token 3.
3: <[0-9]+>
Current char: 1, current token: *
cntMatch=0, stop appending char to current token *.
*: <\*>
Current char: +, current token: 1
cntMatch=0, stop appending char to current token 1.
1: <[0-9]+>
Current char: 3, current token: +
cntMatch=0, stop appending char to current token +.
+: <\+>
Current char: ), current token: 3
cntMatch=0, stop appending char to current token 3.
3: <[0-9]+>
): <\)>

Tokenize [(33+34)*45/32+8*(3*1+3)]:
This tokenization is expected to throw an exception.
Tokens:
Current char: (, current token:
<\(> matches (
cntMatch=1>0, expand token. Current char: 3, current token: (
Current char: 3, current token: (
cntMatch=0, stop appending char to current token (.
(: <\(>
Current char: 3, current token: 3
<[0-9]+> matches 33
cntMatch=1>0, expand token. Current char: +, current token: 33
Current char: +, current token: 33
cntMatch=0, stop appending char to current token 33.
33: <[0-9]+>
Current char: 3, current token: +
cntMatch=0, stop appending char to current token +.
+: <\+>
Current char: 4, current token: 3
<[0-9]+> matches 34
cntMatch=1>0, expand token. Current char: ), current token: 34
Current char: ), current token: 34
cntMatch=0, stop appending char to current token 34.
34: <[0-9]+>
Current char: *, current token: )
cntMatch=0, stop appending char to current token ).
): <\)>
Current char: 4, current token: *
cntMatch=0, stop appending char to current token *.
*: <\*>
Current char: 5, current token: 4
<[0-9]+> matches 45
cntMatch=1>0, expand token. Current char: /, current token: 45
Current char: /, current token: 45
cntMatch=0, stop appending char to current token 45.
45: <[0-9]+>
Current char: 3, current token: /
cntMatch=0, stop appending char to current token /.
ERROR: Invalid token: /
Tokenize [(33+34)*45(32+8*(3-1+3)]:
This tokenization is expected to throw an exception.
Tokens:
Current char: (, current token:
<\(> matches (
cntMatch=1>0, expand token. Current char: 3, current token: (
Current char: 3, current token: (
cntMatch=0, stop appending char to current token (.
(: <\(>
Current char: 3, current token: 3
<[0-9]+> matches 33
cntMatch=1>0, expand token. Current char: +, current token: 33
Current char: +, current token: 33
cntMatch=0, stop appending char to current token 33.
33: <[0-9]+>
Current char: 3, current token: +
cntMatch=0, stop appending char to current token +.
+: <\+>
Current char: 4, current token: 3
<[0-9]+> matches 34
cntMatch=1>0, expand token. Current char: ), current token: 34
Current char: ), current token: 34
cntMatch=0, stop appending char to current token 34.
34: <[0-9]+>
Current char: *, current token: )
cntMatch=0, stop appending char to current token ).
): <\)>
Current char: 4, current token: *
cntMatch=0, stop appending char to current token *.
*: <\*>
Current char: 5, current token: 4
<[0-9]+> matches 45
cntMatch=1>0, expand token. Current char: (, current token: 45
Current char: (, current token: 45
cntMatch=0, stop appending char to current token 45.
45: <[0-9]+>
Current char: 3, current token: (
cntMatch=0, stop appending char to current token (.
(: <\(>
Current char: 2, current token: 3
<[0-9]+> matches 32
cntMatch=1>0, expand token. Current char: +, current token: 32
Current char: +, current token: 32
cntMatch=0, stop appending char to current token 32.
32: <[0-9]+>
Current char: 8, current token: +
cntMatch=0, stop appending char to current token +.
+: <\+>
Current char: *, current token: 8
cntMatch=0, stop appending char to current token 8.
8: <[0-9]+>
Current char: (, current token: *
cntMatch=0, stop appending char to current token *.
*: <\*>
Current char: 3, current token: (
cntMatch=0, stop appending char to current token (.
(: <\(>
Current char: -, current token: 3
cntMatch=0, stop appending char to current token 3.
3: <[0-9]+>
Current char: 1, current token: -
cntMatch=0, stop appending char to current token -.
ERROR: Invalid token: -
[       OK ] LexTest.tokenize2 (3 ms)
[----------] 3 tests from LexTest (5 ms total)

[----------] Global test environment tear-down
[==========] 3 tests from 1 test suite ran. (5 ms total)
[  PASSED  ] 3 tests.
